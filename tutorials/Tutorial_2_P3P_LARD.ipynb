{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb46f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../\n",
    "%pip install -e .\n",
    "%cd tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d52d7",
   "metadata": {},
   "source": [
    "Import the image from the LARD dataset and plot the 4 corner of the runway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a28289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from poseidon.numpy import generate_rotation_matrix_with_angles\n",
    "\n",
    "img = mpimg.imread(\"LARD_example.jpg\")\n",
    "plt.imshow(img)\n",
    "\n",
    "df = pd.read_csv(\"extract_labeling_Bing.csv\", delimiter=\";\")\n",
    "dic = df.to_dict(orient=\"records\")[0]\n",
    "\n",
    "TL = [dic[\"x_TL\"], dic[\"y_TL\"]]\n",
    "plt.scatter(TL[0], TL[1], label=\"Top Left\")\n",
    "\n",
    "TR = [dic[\"x_TR\"], dic[\"y_TR\"]]\n",
    "plt.scatter(TR[0], TR[1], label=\"Top Right\")\n",
    "\n",
    "BL = [dic[\"x_BL\"], dic[\"y_BL\"]]\n",
    "plt.scatter(BL[0], BL[1], label=\"Bottom Left\")\n",
    "\n",
    "BR = [dic[\"x_BR\"], dic[\"y_BR\"]]\n",
    "plt.scatter(BR[0], BR[1], label=\"Bottom Right\")\n",
    "\n",
    "points_2D_LARD = torch.tensor([TL, TR, BL, BR], dtype=torch.float64).unsqueeze(0)\n",
    "points_2D_LARD_np = points_2D_LARD.squeeze(0).numpy()\n",
    "print(\"Points 2D:\\n\", points_2D_LARD)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60449e56",
   "metadata": {},
   "source": [
    "- Compute the rotation matrix (given for this image, the one we want to re-estimate) : from the yaw pitch and rool  \n",
    "- Recover the position matrix (given for this image, the one we want to re-estimate) : with the previous funtion  \n",
    "- Create the intraseca matrix : with the parameters given for this image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation\n",
    "yaw, pitch, roll = dic[\"yaw\"], dic[\"pitch\"], dic[\"roll\"]\n",
    "print(\"(yaw,pitch,roll):\", yaw, pitch, roll)\n",
    "R = torch.tensor(\n",
    "    generate_rotation_matrix_with_angles(yaw, pitch, roll), dtype=torch.float64\n",
    ").unsqueeze(0)\n",
    "print(\"Rotation matrix (R):\")\n",
    "print(R, R.shape)\n",
    "\n",
    "\n",
    "# Position\n",
    "C = torch.tensor(\n",
    "    [[dic[\"lon_cam\"]], [dic[\"lat_cam\"]], [dic[\"alt_cam\"]]], dtype=torch.float64\n",
    ").unsqueeze(0)\n",
    "print(\"Camera position (C):\", C, C.shape)\n",
    "\n",
    "\n",
    "# Intraseca\n",
    "A = torch.tensor([[60, 0, 0], [0, 60, 0], [0, 0, 1]], dtype=torch.float64).unsqueeze(0)\n",
    "A_np = A.squeeze(0).numpy()\n",
    "print(\"Camera intrinsic parameters (A):\")\n",
    "print(A, A.shape)\n",
    "print(A_np, A_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aaa75b",
   "metadata": {},
   "source": [
    "Import the 3D coordinates of the corners :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f19e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"runway_points.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Récupère les positions des points A, B, C, D\n",
    "\n",
    "positions_lat = []\n",
    "\n",
    "for key in [\"B\", \"A\", \"C\", \"D\"]:\n",
    "    coordinate = data[\"CYEG\"][\"20\"][key][\"coordinate\"]\n",
    "    positions_lat.append([coordinate[\"longitude\"], coordinate[\"latitude\"], coordinate[\"altitude\"]])\n",
    "\n",
    "\n",
    "# Conversion en numpy array et torch tensor\n",
    "points_3D_np = np.array(positions_lat)\n",
    "\n",
    "points_3D = torch.tensor(points_3D_np, dtype=torch.float64).unsqueeze(0)\n",
    "\n",
    "print(\"3D points (numpy):\\n\", points_3D_np, points_3D_np.shape)\n",
    "print(\"3D points (torch):\\n\", points_3D, points_3D.shape)\n",
    "\n",
    "from poseidon.torch.utils.before_p3p import projection_all_point3D_to2D\n",
    "\n",
    "points_2D = projection_all_point3D_to2D(points_3D, C, R, A)\n",
    "points_2D_np = points_2D.squeeze(0).numpy()\n",
    "print(\"2D points (torch) : \\n\", points_2D, points_2D.shape)\n",
    "print(\"2D\", points_2D_LARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5b560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create of the 3D figure\n",
    "print(\"3D points (torch):\\n\", points_3D, points_3D.shape)\n",
    "print(\"Camera position (C):\", C, C.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "ax.scatter(C[:, 0].squeeze(), C[:, 1].squeeze(), C[:, 2].squeeze(), color=\"orange\")\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    Pi = points_3D[:, i].squeeze()\n",
    "    print(f\"P{i+1} position:\", Pi)\n",
    "    ax.scatter(*Pi, color=\"black\")\n",
    "    ax.text(*Pi, f\"$P_{i+1}$\")\n",
    "    ax.plot(\n",
    "        [C[:, 0].squeeze(), Pi[0]], [C[:, 1].squeeze(), Pi[1]], [C[:, 2].squeeze(), Pi[2]], \"k--\"\n",
    "    )\n",
    "    f = Pi - C\n",
    "\n",
    "# Set axis limits to visualize a 4x4x4 space centered around zero\n",
    "\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "ax.set_title(\"The three 3D Points use for P3P\")\n",
    "ax.view_init(elev=15, azim=30)  # élévation de 60°, azimut de 30°\n",
    "\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbb19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from poseidon.torch import compute_features_vectors\n",
    "\n",
    "features_vect = compute_features_vectors(points_3D, C, R)\n",
    "print(\"Feature vectors:\\n\", features_vect, features_vect.shape)\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def compute_feature_vectors_from_2D(points_2D, A):\n",
    "    fet = []\n",
    "\n",
    "    fx = A[0, 0, 0]\n",
    "    fy = A[0, 1, 1]\n",
    "    cx = A[0, 0, 2]\n",
    "    cy = A[0, 1, 2]\n",
    "\n",
    "    print(\"fx, fy, cx, cy:\", fx, fy, cx, cy)\n",
    "\n",
    "    for i in range(3):\n",
    "        # points_2D shape: [1, 3, 2], so points_2D[0, i] is [u, v]\n",
    "        u, v = points_2D[0, i]\n",
    "\n",
    "        # Normalize using intrinsics\n",
    "        f = torch.tensor([(u - cx) / fx, (v - cy) / fy, 1.0], dtype=torch.float64)\n",
    "\n",
    "        # Normalize vector to make it unitary\n",
    "        f = f / torch.linalg.norm(f)\n",
    "\n",
    "        fet.append(f)\n",
    "\n",
    "    return torch.stack(fet, dim=0)  # Shape: [3, 3]\n",
    "\n",
    "\n",
    "ft = compute_feature_vectors_from_2D((points_2D_LARD[:, :3]), A).unsqueeze(0)\n",
    "# print(\"Feature vectors from 2D points:\\n\", ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c7525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create of the 3D figure\n",
    "print(\"3D points (torch):\\n\", points_3D, points_3D.shape)\n",
    "print(\"Camera position (C):\", C, C.shape)\n",
    "print(\"Feature vectors (ft):\", ft, ft.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "ax.scatter(C[:, 0].squeeze(), C[:, 1].squeeze(), C[:, 2].squeeze(), color=\"orange\")\n",
    "origin = np.array([C[:, 0].item(), C[:, 1].item(), C[:, 2].item()])\n",
    "\n",
    "\n",
    "ft_sq = ft.squeeze(0).numpy()\n",
    "\n",
    "for i in range(3):\n",
    "    Pi = points_3D[:, i].squeeze()\n",
    "    print(f\"P{i+1} position:\", Pi)\n",
    "    ax.scatter(*Pi, color=\"black\")\n",
    "    ax.text(*Pi, f\"$P_{i+1}$\")\n",
    "    ax.plot(\n",
    "        [C[:, 0].squeeze(), Pi[0]], [C[:, 1].squeeze(), Pi[1]], [C[:, 2].squeeze(), Pi[2]], \"k--\"\n",
    "    )\n",
    "print(\"ft_sq[:,0]:\", ft_sq[:, 0])  # x composantes des vecteurs\n",
    "print(\"ft_sq[:,1]:\", ft_sq[:, 1])  # y composantes\n",
    "print(\"ft_sq[:,2]:\", ft_sq[:, 2])  # z composantes\n",
    "print(\"origin:\", origin)\n",
    "\n",
    "scale = 1\n",
    "\n",
    "ax.quiver(\n",
    "    C[:, 0].item(),\n",
    "    C[:, 1].item(),\n",
    "    C[:, 2].item(),\n",
    "    ft_sq[:, 0] * scale,\n",
    "    ft_sq[:, 1] * scale,\n",
    "    ft_sq[:, 2] * scale,\n",
    "    color=[\"r\", \"g\", \"b\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Set axis limits to visualize a 4x4x4 space centered around zero\n",
    "\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "ax.set_title(\"The three 3D Points use for P3P\")\n",
    "\n",
    "ax.set_xlim(C[:, 0].item() - 1, C[:, 0].item() + 1)\n",
    "ax.set_ylim(C[:, 1].item() - 1, C[:, 1].item() + 1)\n",
    "ax.set_zlim(C[:, 2].item() - 40, C[:, 2].item() + 1)\n",
    "\n",
    "\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2fdfc5",
   "metadata": {},
   "source": [
    "Test with open cv : no solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poseidon.numpy import solve_reformat_p3p_solutions\n",
    "\n",
    "solutions_opencv = solve_reformat_p3p_solutions(points_3D_np[:3, :], points_2D_LARD_np[:3, :], A_np)\n",
    "print(\"Solutions from OpenCV P3P:\\n\", solutions_opencv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poseidon.torch import P3P, find_best_solution_P3P_batch\n",
    "\n",
    "solutions_torch = P3P(points_3D, features_vect)\n",
    "print(\"Solutions from Poseidon P3P:\\n\", solutions_torch)\n",
    "\n",
    "\n",
    "R_solutions, C_solutions, error = find_best_solution_P3P_batch(\n",
    "    solutions_torch, points_2D, points_3D, A\n",
    ")\n",
    "print(\"Rotation solutions (R):\\n\", R_solutions)\n",
    "print(\"R\", R)\n",
    "print(\"Camera position solutions (C):\\n\", C_solutions)\n",
    "print(\"C\", C)\n",
    "print(\"Error for each solution:\\n\", error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
