{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb46f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../\n",
    "%pip install -e .\n",
    "%cd tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e359d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d52d7",
   "metadata": {},
   "source": [
    "### 1. Import and runway from the LARD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a28289",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"LARD_example.jpg\")\n",
    "plt.imshow(img)\n",
    "\n",
    "df = pd.read_csv(\"extract_labeling_Bing.csv\", delimiter=\";\")\n",
    "dic = df.to_dict(orient=\"records\")[0]\n",
    "\n",
    "TL = [dic[\"x_TL\"], dic[\"y_TL\"]]\n",
    "plt.scatter(TL[0], TL[1], label=\"Top Left\")\n",
    "\n",
    "TR = [dic[\"x_TR\"], dic[\"y_TR\"]]\n",
    "plt.scatter(TR[0], TR[1], label=\"Top Right\")\n",
    "\n",
    "BL = [dic[\"x_BL\"], dic[\"y_BL\"]]\n",
    "plt.scatter(BL[0], BL[1], label=\"Bottom Left\")\n",
    "\n",
    "BR = [dic[\"x_BR\"], dic[\"y_BR\"]]\n",
    "plt.scatter(BR[0], BR[1], label=\"Bottom Right\")\n",
    "\n",
    "points_2D_LARD = torch.tensor([TL, TR, BL, BR], dtype=torch.float64).unsqueeze(0)\n",
    "points_2D_LARD_np = points_2D_LARD.squeeze(0).numpy()\n",
    "print(\"Points 2D:\\n\", points_2D_LARD)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60449e56",
   "metadata": {},
   "source": [
    "### 2. Compute the rotation matrix\n",
    "- from the yaw pitch and rool  \n",
    "- given for this image, the one we want to re-estimate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8adaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poseidon.numpy import generate_rotation_matrix_with_angles\n",
    "\n",
    "yaw, pitch, roll = dic[\"yaw\"], dic[\"pitch\"], dic[\"roll\"]\n",
    "print(\"yaw,pitch,roll :\", yaw, pitch, roll, \"\\n\")\n",
    "\n",
    "R = torch.tensor(\n",
    "    generate_rotation_matrix_with_angles(yaw, pitch, roll), dtype=torch.float64\n",
    ").unsqueeze(0)\n",
    "\n",
    "print(\"Rotation matrix (R): \\n\", R, \"\\n\", R.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd7bded",
   "metadata": {},
   "source": [
    "### 3. Recover the position matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.tensor(\n",
    "    [[dic[\"lon_cam\"]], [dic[\"lat_cam\"]], [dic[\"alt_cam\"]]], dtype=torch.float64\n",
    ").unsqueeze(0)\n",
    "\n",
    "print(\"Camera position (C) : \\n\", C, \"\\n\", C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a51007",
   "metadata": {},
   "source": [
    "### 4. Create the intraseca matrix of the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b1a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intraseca\n",
    "A = torch.tensor([[60, 0, 0], [0, 60, 0], [0, 0, 1]], dtype=torch.float64).unsqueeze(0)\n",
    "\n",
    "print(\"Camera intrinsic parameters (A): \\n\", A, \"\\n\", A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aaa75b",
   "metadata": {},
   "source": [
    "### 5. Import the 3D coordinates of the corners "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f19e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the runway points data\n",
    "with open(\"runway_points.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the 3D coordinates of the corners\n",
    "positions_lat = []\n",
    "for key in [\"B\", \"A\", \"C\", \"D\"]:\n",
    "    coordinate = data[\"CYEG\"][\"20\"][key][\"coordinate\"]\n",
    "    positions_lat.append([coordinate[\"longitude\"], coordinate[\"latitude\"], coordinate[\"altitude\"]])\n",
    "\n",
    "# Convert to numpy array and torch tensor\n",
    "points_3D_np = np.array(positions_lat)\n",
    "points_3D = torch.tensor(points_3D_np, dtype=torch.float64).unsqueeze(0)\n",
    "\n",
    "print(\"3D points (torch):\\n\", points_3D, \"\\n\", points_3D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9388a0d",
   "metadata": {},
   "source": [
    "Plot the four 3D points : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddec887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create of the 3D figure\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# Plot the camera center\n",
    "ax.scatter(C[:, 0].squeeze(), C[:, 1].squeeze(), C[:, 2].squeeze(), color=\"orange\")\n",
    "\n",
    "# Plot the features points\n",
    "for i in range(4):\n",
    "    Pi = points_3D[:, i].squeeze()\n",
    "    print(f\"P{i+1}:\", Pi)\n",
    "    ax.scatter(*Pi, color=\"black\")\n",
    "    ax.text(*Pi, f\"$P_{i+1}$\")\n",
    "    ax.plot(\n",
    "        [C[:, 0].squeeze(), Pi[0]], [C[:, 1].squeeze(), Pi[1]], [C[:, 2].squeeze(), Pi[2]], \"k--\"\n",
    "    )\n",
    "\n",
    "# Set axis labels and limits\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "\n",
    "# Plot the figure\n",
    "ax.set_title(\"The three 3D Points use for P3P\")\n",
    "ax.view_init(elev=15, azim=30)  # élévation de 60°, azimut de 30°\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651842a1",
   "metadata": {},
   "source": [
    "### 6. Generate the 2D points for the P3P problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poseidon.torch import generate_synthetic_2D3Dpoints\n",
    "\n",
    "points_2D = generate_synthetic_2D3Dpoints(R, C, A, points_3D)\n",
    "points_2D_np = points_2D.squeeze(0).numpy()\n",
    "\n",
    "print(\"Computed 2D points : \\n\", points_2D, points_2D.shape)\n",
    "print(\"\\n LARD dataset 2D points : \\n\", points_2D_LARD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115e5c10",
   "metadata": {},
   "source": [
    "### 7. Compute the features vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a792c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poseidon.torch import get_feature_vectors\n",
    "\n",
    "features_vectors = get_feature_vectors(points_2D[:, :3], A)\n",
    "print(\"Features vectors:\\n\", features_vectors, features_vectors.shape)\n",
    "# Warning: Only the first 3 points are considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poseidon.torch import compute_features_vectors, projection_all_point3D_to2D\n",
    "\n",
    "old_points_2D = projection_all_point3D_to2D(points_3D, C, R, A)\n",
    "old_features_vectors = compute_features_vectors(points_3D, C, R)\n",
    "print(\"Old features vectors:\\n\", old_features_vectors, \"\\n\", old_features_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2fdfc5",
   "metadata": {},
   "source": [
    "### Test with open cv : no solution found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poseidon.numpy import solve_reformat_p3p_solutions\n",
    "\n",
    "# Convert intraseca matrix A to numpy array\n",
    "A_np = A.squeeze(0).numpy()\n",
    "\n",
    "# Apply the P3P algorithm from openCV\n",
    "solutions_opencv = solve_reformat_p3p_solutions(points_3D_np[:3, :], points_2D_LARD_np[:3, :], A_np)\n",
    "print(\"Solutions from OpenCV P3P:\\n\", solutions_opencv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3789a9f",
   "metadata": {},
   "source": [
    "### Apply the P3P algorithm in torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poseidon.torch import P3P\n",
    "\n",
    "solutions_torch = P3P(points_3D, old_features_vectors)\n",
    "print(\"Solutions from Poseidon P3P:\\n\", solutions_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7adffba",
   "metadata": {},
   "source": [
    "### Find the best solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poseidon.torch import find_best_solution_P3P_batch\n",
    "\n",
    "R_solutions, C_solutions, error = find_best_solution_P3P_batch(\n",
    "    solutions_torch, points_2D, points_3D, A\n",
    ")\n",
    "print(\"Rotation solutions (R):\\n\", R_solutions)\n",
    "print(\"R\", R)\n",
    "print(\"Camera position solutions (C):\\n\", C_solutions)\n",
    "print(\"C\", C)\n",
    "print(\"Error for each solution:\\n\", error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
